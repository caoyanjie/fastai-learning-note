{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$> pip install kaggle --upgrade   # 安装 kaggle\n",
    "$> mkdir -p ~/.kaggle/            # 创建 .kaggle 文件夹\n",
    "$> mv kaggle.json ~/.kaggle/      # 把从 kaggle 网站下载的 kaggle.json 复制到 .kaggle 文件夹内（1.注册kaggle账户；2.用户信息->创建令牌，会下载 kaggle.json）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Config.data_path()/'planet'\n",
    "path.mkdir(exist_ok=True)\n",
    "path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 下载 kaggle 数据\n",
    "$> kaggle competitions download -c planet-understanding-the-amazon-from-space -f train-jpg.tar.7z -p ...\n",
    "$> kaggle competitions download -c planet-understanding-the-amazon-from-space -f train_v2.csv -p {pat} ...\n",
    "$> unzip -q -n {path}/train_v2.csv.zip -d {path}\n",
    "\n",
    "# 下载软件，解压数据\n",
    "$> conda install -y -c haasad eidl7zip\n",
    "$> 7za -bd -y -so x {path}/train-jpg.tar.7z | tar xf - -C {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclassification 多标签分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看标签文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'train_v2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data block API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "src = (ImageFileList.from_folder(path)\n",
    "       .label_from_csv('train_v2.csv', sep=' ', folder='train-jpg', suffix='.jpg')\n",
    "       .random_split_by_pct(0.2))  # 随机划出20%作为验证机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)  # flip_vert:反转图像，warp:透视变换\n",
    "data = (src.datasets().transform(tfms, size=128).databunch().normalize(imagenet_stats))\n",
    "data.show_batch(row=3, figsize=(10, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_02(inp, targ):\n",
    "    return accuracy_thresh(inp, targ, thresh=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = models.resnet50\n",
    "acc_02 = partial(accuracy_thresh, thresh=0.2)  # 偏函数，用参数为thresh=0.2调用accuracy_thresh生成新函数\n",
    "f_score = partial(fbeta, thresh=0.2)  # 预测概率的阈值，概率超过该阈值就认为识别到了该类\n",
    "learn = cnn_learner(data, arch, metrics=[acc_02, f_score])\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01    # 在上图中下降最快的地方\n",
    "learn.fit_one_cycle(5, slice(lr))\n",
    "learn.save('stage-1-rn50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, slice(1e-5, lr/5))  # 在上图中突然飙升的地方往前10倍....3.5的8分20秒\n",
    "learn.save('stage-2-rn50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用迁移学习，将上面擅长识别128*128卫星图片的模型学会擅长识别256*256的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (src.datasets(ImageMultiDataset)\n",
    "       .transform(trms, size=256)\n",
    "       .databunch().normalize(imagenet_stats))\n",
    "learn.data = data          # 新的数据替换为新的databunch(256*256)\n",
    "data.train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()             # freeze后在之前的基础上只要训练最后几层\n",
    "learnl.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = le-2/2                # 从上图中可知，因为是已经训练好的一个模型了(对128*128效果很好的模型了)所有没有得到像之前那么陡峭的曲线，选择一个在曲线攀升前的值，再缩小10倍， \n",
    "learn.fit_one_cycle(5, slice(lr))\n",
    "learn.save('stage-1-256-rn50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 也可以不用迁移学习，用之前的方法，重新训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, slice(1e-5, lr/5))\n",
    "learn.recorder.plot_losses()\n",
    "learn.save('stage-2-256-rn50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation with CamVid  图像分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.CAMVID)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lb1 = path/'labels'\n",
    "path_img = path/'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = get_image_files(path_img)\n",
    "fnames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb1_names = get_image_files(path_lb1)\n",
    "lb1_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = fnames[0]\n",
    "img = open_image(img_f)                                # 打开普通图片文件用 open_image()\n",
    "img.show(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_y_fn = lambda x: path_lb1/f'{x.stem}_P{x.suffix}'  # 把带后缀P的文件保存到一处\n",
    "mask = open_mask(get_y_fn(img_f))                      # 打开保存的文件，打开带标注的图像文件用 open_mask()\n",
    "mask.show(figsize=(5,5), alpha=1)                      # 显示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_size = np.array(mask.shape[1:])\n",
    "src_size, mask.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 codes.txt 文件内容\n",
    "codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
    "codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets 通过 dataset api 创建 Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = src_size // 2\n",
    "bs = 8                                                    # 随机梯度下降的随机批次大小，根据GPU内存调整适当值\n",
    "src = (ImageFileList.from_folder(path_img)                # 加载图片文件列表\n",
    "       .label_from_func(get_y_fn)                         # 创建标签\n",
    "       .split_by_fnames_file('../valid.txt'))             # 拆分训练集和验证集（不随机是因为数据为视频帧，如果随机就可能相邻两帧一个在训练集一个在验证集）\n",
    "data = (src.datasets(SegmentationDataset, classes=codes)  # codes 解释每个数字代表什么类别\n",
    "       .transform(get_transforms(), size=size, tfm_y=True)\n",
    "       .databunch(bs=bs)\n",
    "       .normalize(imagenet_stats))\n",
    "data.show_batch(2， figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(2, figsize=(10,7), ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "void_code = name2id['Void']\n",
    "\n",
    "def acc_camvid(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    mask = target != void_code\n",
    "    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()\n",
    "\n",
    "metrics = acc_camvid\n",
    "# metrics = accuracy\n",
    "\n",
    "learn = Learner.create_unet(data, models.resnet34, metrics=metrics)#.to_fp1y()     # 如果GPU内存严重不足，加上to_fp1y()用混精度训练，得到一个用16位精度训练的模型(需要由最新的CUDA)驱动 \n",
    "lr_find(learn)\n",
    "learn.recorer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "learn.fit_one_cycle(10, slice(lr))\n",
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解冻，再训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1')\n",
    "learn.unfreeze()\n",
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = slice(1e-5, lr/5)\n",
    "learn.fit_one_cycle(12, lrs)\n",
    "learn.recorder.plot_losses()  # 画出损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr()      # 画出学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Go big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = src_size         # 数据为完整图像大小\n",
    "bs = 4\n",
    "data = (src.datasets(SegmentationDataset, classes=codes)\n",
    "       .transform(get_transforms(), size=size, tfm_y=True)\n",
    "       .databunch(bs=bs)\n",
    "       .normalize(imagenet_stats))\n",
    "\n",
    "# 因为 GPU 内存不够用，所以重启内核，新建一个 learn，加载上次保存的权重\n",
    "learn = Learner.create_unet(data, models.resnet34, metrics=metrics)\n",
    "learn.load('stage-2')\n",
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "learn.fit_one_cycle(10, slice(lr))\n",
    "learn.save('stage-1-big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1-big')\n",
    "learn.unfreeze()\n",
    "lrs = slice(1e-6, lr)\n",
    "learn.fit_one_cycle(10, lrs, wd=1e-3)\n",
    "learn.save('stage-2-big')              # 'stage-2-big-fp16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-2-big')\n",
    "learn.show_results()       # 看看结果和真实值相比如何"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with BIWI head pose dataset (用BIWI头部姿势数据集做图像回归)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and converting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/biwi_head_pose')\n",
    "cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)\n",
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = path/'09'/'frame_00667_rgb.jpg'\n",
    "def img2txt_name(f):\n",
    "    return f'{str(f)[:-7]}pose.txt'\n",
    "img = open_image(fname)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = np.genfromtxt(img2txt_name(fname), skip_header=3)\n",
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_biwi(coords):\n",
    "    c1 = coords[0] * cal[0][0]/coords[2] + cal[0][2]\n",
    "    c2 = coords[1] * cal[1][1]/coords[2] + cal[1][2]\n",
    "    return tensor([c2, c1])\n",
    "\n",
    "def get_ctr(f):\n",
    "    ctr = np.genfromtxt(img2txt_name(f), skip_header=3)\n",
    "    return convert_biwi(ctr)\n",
    "\n",
    "def get_ip(img, ptf):\n",
    "    return ImagePoints(FlowField(img.size, pts), scale=True)\n",
    "\n",
    "ctr = get_ctr(fname)\n",
    "img.show(y=get_ip(img, ctr), figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (ImageFileList.from_folder(path)\n",
    "       .label_from_func(get_ctr)\n",
    "       .split_by_valid_func(lambda o: o[0].parent.name == '13')\n",
    "       .datasets(PointsDataset)\n",
    "       .transform(get_transforms(), tfm_y=True, size=(120, 160))\n",
    "       .databunch().normalize(imagenet_stats)\n",
    "       )\n",
    "data.show_batch(3, figsize=(9, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet34)\n",
    "learn.loss_func = MSELossFlat()    # 均方误差损失函数\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-2\n",
    "learn.fit_one_cycle(5, slice(lr))\n",
    "learn.save('stage-1')\n",
    "learn.show_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
